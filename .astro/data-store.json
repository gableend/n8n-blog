[["Map",1,2,9,10],"meta::meta",["Map",3,4,5,6,7,8],"astro-version","5.7.13","content-config-digest","948914bef5b871f2","astro-config-digest","{\"root\":{},\"srcDir\":{},\"publicDir\":{},\"outDir\":{},\"cacheDir\":{},\"compressHTML\":true,\"base\":\"/\",\"trailingSlash\":\"ignore\",\"output\":\"static\",\"scopedStyleStrategy\":\"attribute\",\"build\":{\"format\":\"directory\",\"client\":{},\"server\":{},\"assets\":\"_astro\",\"serverEntry\":\"entry.mjs\",\"redirects\":true,\"inlineStylesheets\":\"auto\",\"concurrency\":1},\"server\":{\"open\":false,\"host\":false,\"port\":4321,\"streaming\":true,\"allowedHosts\":[]},\"redirects\":{},\"image\":{\"endpoint\":{\"route\":\"/_image\"},\"service\":{\"entrypoint\":\"astro/assets/services/sharp\",\"config\":{}},\"domains\":[],\"remotePatterns\":[]},\"devToolbar\":{\"enabled\":true},\"markdown\":{\"syntaxHighlight\":{\"type\":\"shiki\",\"excludeLangs\":[\"math\"]},\"shikiConfig\":{\"langs\":[],\"langAlias\":{},\"theme\":\"github-dark\",\"themes\":{},\"wrap\":false,\"transformers\":[]},\"remarkPlugins\":[],\"rehypePlugins\":[],\"remarkRehype\":{},\"gfm\":true,\"smartypants\":true},\"security\":{\"checkOrigin\":true},\"env\":{\"schema\":{},\"validateSecrets\":false},\"experimental\":{\"clientPrerender\":false,\"contentIntellisense\":false,\"responsiveImages\":false,\"headingIdCompat\":false,\"preserveScriptOrder\":false},\"legacy\":{\"collections\":false}}","blog",["Map",11,12],"n8n-icp-workflow",{"id":11,"data":13,"body":17,"filePath":18,"digest":19,"rendered":20,"legacyId":57},{"title":14,"description":15,"date":16},"From Idea to ICP: My first n8n AI workflow","How I used n8n, OpenAI, and Google tools to automate Ideal Customer Profile (ICP) creation and analysis at scale.",["Date","2025-05-21T00:00:00.000Z"],"As a marketer, I love turning raw data into actionable insights. I've been a heavy ChatGPT Pro user for some time now, using features like Deep Research, Operator, and CustomGPTs for different parts of the product marketer’s playbook. While powerful, I still found it challenging to establish repeatable processes. This all changed when I added n8n, an intuitive, low-code workflow automation tool aligned perfectly with the snowballing agentic AI movement.\n\nOne area I've consistently struggled with in ChatGPT is reliable data manipulation and enrichment, especially at scale. Keeping insights up-to-date manually was cumbersome and error-prone. For example, in a fast-growing SaaS business, maintaining an accurate, real-time Ideal Customer Profile (ICP) is critical, as movements can be surprising.\n\nThis is the story of how, in just a few hours, I used n8n to to fully automate ICP creation using TheirStack, the mighty OpenAI API, and trusty Google tools (Sheets and Docs).\n\n\n## 🧰 Toolkit overview\n\nChoosing the right tools made all the difference:\n\n- **n8n**: n8n: An intuitive, low-code workflow automation platform, allowing me to visually orchestrate tasks between APIs and tools.\n\n\n- **TheirStack**: Provided detailed technology usage insights for firmographic enrichment and deeper understanding of market segments.\n\n\n- **OpenAI API (GPT-4)**: Needs no introduction. Thanks to precise prompts honed in previous ChatGPT sessions, GPT-4 executed the final ICP analysis effortlessly. It also handled basic enrichment tasks, filling in missing industry, revenue, and employee data.\n\n\n- **Google Sheets & Docs**: Google Sheets served as my primary datastore, while Google Docs neatly formatted the final ICP for easy sharing.\n\n\nTogether, these tools created a powerful, repeatable workflow.\n\n\n## 🥞 TheirStack: My source of tech truth\nTo put my toolkit to the test, I decided to use n8n itself as my guinea pig technology. TheirStack maintains an extensive database of technology usage across thousands of companies, making it a great resource to find n8n customers.\n\nI filtered and quickly had data on hundreds of companies currently using n8n. This dataset included details like industry, company size, revenue ranges, and geographic location, all essential firmographic elements for ICP analysis. Unfortunately, much like many data sources (I'm looking at you, Salesforce CRM!), the data was a little patchy. In my workflow, I needed to corral and enrich the data to fill the pesky gaps.\n\n\u003Cp style=\"text-align: center;\">\u003Cb>TheirStack Company Search\u003C/b>\u003C/p>\n\n\u003Ccenter>\u003Cimg src=\"/images/01-theirstack-table.png\" style=\"width:700px;\" />\u003C/center>\n\n## 🚦 Getting started with n8n\n\nGetting started with n8n was easy. Just connect your Google account and you get access to their free tier. In fact, I was able to complete my entire project on this tier.\n\nYou start by creating a new workflow and establishing your trigger. If I were setting this up for real, I would have chosen a scheduled trigger to pull and refresh data periodically, or have triggered it via a Webhook when data changed. For my initial exploration I went with a manual trigger to keep things simple.\n\nThe n8n UI is intuitive, and I was able to get going quickly. As a habitual ChatGPT user, I had it open on the side and relied on it to support me throughout the process. While there is an AI chatbot embedded in n8n, I felt more comfortable with the familiar GPT interface. I'll dig deeper into n8n's own AI capabilities as I build out future automations.\n\n\u003Cp style=\"text-align: center;\">\u003Cb>n8 Workflow Canvas\u003C/b>\u003C/p>\n\n\u003Ccenter>\u003Cimg src=\"/images/02-n8n-workflow-canvas.png\" style=\"width:700px\" />\u003C/center>\n\n\n\n## 🎣 Pulling data from TheirStack\n\nWith n8n set up and ready to go, my next step was to pull the technology usage data directly from TheirStack. Conveniently, they provide an n8n integration button that lets you copy the required HTTP request and simply paste it to your n8n workflow, automatically creating the node for you.\n\nOf course, things are rarely seamless the first time around. There was some initial messing about figuring out how to obtain my API Key and correctly add it to the node configuration. After a bit of trial and error, I got the connection working, only to realise I needed a paid TheirStack subscription to fully enable the API. Subscription sorted, I successfully pulled the data using the handy \"Test Workflow\" feature built into n8n.\n\nWith the data flowing, the next step was straightforward. I connected a Google Sheets node to my workflow. With just a few clicks, I mapped the JSON data fields to columns in my Google Sheet and was able to populate a single row.\n\nAt this stage, things got a little tricky. I wanted to populate 500 records, the maximum my TheirStack account would allow via the API (you have to be a superuser to do more), so I would have a representative set of n8n customers from major economies. I had some difficulties because I couldn't get my workflow to loop through each record in turn. I initially went down the road of using a \"Loop Over Items\" node to try and solve for this but struggled to get that working.\n\nI made a breakthrough when I realized I could share the input and output data from a node with ChatGPT by copying and pasting it, providing some context. ChatGPT understood my issue and suggested using a Code node to break down my large dataset into individual records.\n\nI haven’t really been let loose on code since my early days as a Java programmer back in the early 2000s, and aside from some basic scripting for demos in various pre-sales roles, my coding skills are a little rusty. Thankfully, having GPT generate any necessary code worked just fine throughout this project. Sometimes it took a few attempts, but we always got there.\n\nWith that hurdle overcome, I had a fully populated Google Sheet containing my 500 records, ready for further enrichment and analysis.\n\n\n\n## 🧼 Enriching the dirty data\n\nWith my dataset now safely stored in Google Sheets, the next challenge emerged: addressing the patchy or incomplete data I'd mentioned earlier. Missing or inconsistent data points such as industry classification, revenue, or employee counts posed a problem for the upcoming ICP analysis. I needed complete and consistent firmographic data to ensure accurate, meaningful insights.\n\nTo solve this I used a simple \"If\" node in n8n to check for missing data, routing any problematic records to an OpenAI node for enrichment. It was crucial to be explicit with GPT-4, ensuring it always used a consistent output format. After some trial and error, I had a prompt that worked consistently.\n\n\u003Cp style=\"text-align: center;\">\u003Cb>GPT Enrichment Prompt\u003C/b>\u003C/p>\n\n\u003Ccenter>\u003Cimg src=\"/images/03-gpt-prompt.png\" style=\"width:700px\" />\u003C/center>\n\n\n\nThis structured approach allowed GPT-4 to reliably fill in gaps without adding unnecessary noise. Once enriched, I fed the cleaned data back into Google Sheets, resulting in a fully structured and reliable dataset. My previously \"dirty\" data was now clean, complete, and ready for ICP analysis.\n\n\u003Cp style=\"text-align: center;\">\u003Cb>Final n8n Enrichment Workflow\u003C/b>\u003C/p>\n\n\u003Ccenter>\u003Cimg src=\"/images/04-final-workflow.png\" style=\"width:700px\" />\u003C/center>\n\n## 🧠 Summarizing data and running ICP analysis\n\nWith my clean list of 500 n8n customers and their firmographic details in place, the next step was to segment the data. Alongside basic counts by industry and country I needed to bucket the numerical data (revenue and number of employees) into segments like \"Small, Medium, Large\" for easy analysis. To do this I used a \"Summarize\" node to split the data as required. \n\nSoon I hit another roadbump in that OpenAI was struggling to make sense of the multiple datasets and would seem to hang thinking. With some help from n8n's AI assistant (which accesses documentation and community content) I was able to create a simple input for the LLM with an \"Edit Fields\" node and another Code node.\n\n## ✨ AI-Powered ICP generation\n\nWith the data ready for analysis the next step was to have GPT do the ICP analysis. To do this I crafted the prompt shown below, referencing my summarized data. I kept it simple for illustration. Much more would be possible with richer input data.\n\n\u003Cp style=\"text-align: center;\">\u003Cb>GPT ICP Prompt\u003C/b>\u003C/p>\n\n\u003Ccenter>\u003Cimg src=\"/images/05-icp-prompt.png\" style=\"width:700px\" />\u003C/center>\n\nThe final step was automating the delivery of insights. By connecting n8n directly to Google Docs using OAuth, the AI-generated ICP analysis was formatted and ready for easy sharing. Note: In reality, I would spend more time on formatting, but as a proof of concept this was good to go.\n\n\u003Cp style=\"text-align: center;\">\u003Cb>ICP Analysis in Google Doc\u003C/b>\u003C/p>\n\n\u003Ccenter>\u003Cimg src=\"/images/06-gdoc-output-ICP.png\" style=\"width:700px\" />\u003C/center>\n\n\n\nI did all of the summarizing and ICP analysis and Google Doc steps in a separate workflow. I'm sure I could have done it in one, but breaking it up kept the overall layout manageable.\n\n\n\n\u003Cp style=\"text-align: center;\">\u003Cb>Summarizing and ICP Analysis\u003C/b>\u003C/p>\n\n\u003Ccenter>\u003Cimg src=\"/images/07-second-workflow.png\" style=\"width:700px\" />\u003C/center>\n\n\n\n\n\n## 🎓 Lessons learned\n\nUsing n8n to automate this workflow was next level vs using GPT as a copilot. Whilst I could (and have) got to similar outputs through prompting alone, and manually manipulating spreadsheets, using automation to solidify a repeatable workflow will be a game changer in time saved for this kind of analysis moving forward.\n\nKey takeaways from this journey:\n\n- **Prep is critical**: Enrich before you analyze.\n- **n8n as glue**: Seamlessly connects tools.\n- **LLMs in automation**: Move beyond prompting—enable repeatable, scalable insight generation.\n\n\n\n##  🏁 Final thoughts\n\nMy ICP analysis was simple, focusing only on firmographic data, as a proof of concept. In reality, to build out the full ICP, I would be bringing in multiple 1st party data sources, to augment 3rd party, and analysing technographics, psychographics, business situation and operating model too. \n\nn8n is clearly a powerful centerpoint for automating and scaling modern marketing operations. This leaves me with an excellent first impression of a platform truly positioned at the intersection of low-code and AI. I’m looking forward to experimenting with some additional automations to take on more of the product marketing playbook, like identifying use case clusters or supporting segmentation-driven GTM plays.\n\n> As a product marketer, what excites me most is how n8n enables not just automation, but repeatable insight generation—unlocking many opportunities for faster GTM cycles, richer segmentation, and smarter decisions at scale.","src/content/blog/n8n-icp-workflow.md","76c2c8d194802f46",{"html":21,"metadata":22},"\u003Cp>As a marketer, I love turning raw data into actionable insights. I’ve been a heavy ChatGPT Pro user for some time now, using features like Deep Research, Operator, and CustomGPTs for different parts of the product marketer’s playbook. While powerful, I still found it challenging to establish repeatable processes. This all changed when I added n8n, an intuitive, low-code workflow automation tool aligned perfectly with the snowballing agentic AI movement.\u003C/p>\n\u003Cp>One area I’ve consistently struggled with in ChatGPT is reliable data manipulation and enrichment, especially at scale. Keeping insights up-to-date manually was cumbersome and error-prone. For example, in a fast-growing SaaS business, maintaining an accurate, real-time Ideal Customer Profile (ICP) is critical, as movements can be surprising.\u003C/p>\n\u003Cp>This is the story of how, in just a few hours, I used n8n to to fully automate ICP creation using TheirStack, the mighty OpenAI API, and trusty Google tools (Sheets and Docs).\u003C/p>\n\u003Ch2 id=\"-toolkit-overview\">🧰 Toolkit overview\u003C/h2>\n\u003Cp>Choosing the right tools made all the difference:\u003C/p>\n\u003Cul>\n\u003Cli>\n\u003Cp>\u003Cstrong>n8n\u003C/strong>: n8n: An intuitive, low-code workflow automation platform, allowing me to visually orchestrate tasks between APIs and tools.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>TheirStack\u003C/strong>: Provided detailed technology usage insights for firmographic enrichment and deeper understanding of market segments.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>OpenAI API (GPT-4)\u003C/strong>: Needs no introduction. Thanks to precise prompts honed in previous ChatGPT sessions, GPT-4 executed the final ICP analysis effortlessly. It also handled basic enrichment tasks, filling in missing industry, revenue, and employee data.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Google Sheets &#x26; Docs\u003C/strong>: Google Sheets served as my primary datastore, while Google Docs neatly formatted the final ICP for easy sharing.\u003C/p>\n\u003C/li>\n\u003C/ul>\n\u003Cp>Together, these tools created a powerful, repeatable workflow.\u003C/p>\n\u003Ch2 id=\"-theirstack-my-source-of-tech-truth\">🥞 TheirStack: My source of tech truth\u003C/h2>\n\u003Cp>To put my toolkit to the test, I decided to use n8n itself as my guinea pig technology. TheirStack maintains an extensive database of technology usage across thousands of companies, making it a great resource to find n8n customers.\u003C/p>\n\u003Cp>I filtered and quickly had data on hundreds of companies currently using n8n. This dataset included details like industry, company size, revenue ranges, and geographic location, all essential firmographic elements for ICP analysis. Unfortunately, much like many data sources (I’m looking at you, Salesforce CRM!), the data was a little patchy. In my workflow, I needed to corral and enrich the data to fill the pesky gaps.\u003C/p>\n\u003Cp style=\"text-align: center;\">\u003Cb>TheirStack Company Search\u003C/b>\u003C/p>\n\u003Ccenter>\u003Cimg src=\"/images/01-theirstack-table.png\" style=\"width:700px;\">\u003C/center>\n\u003Ch2 id=\"-getting-started-with-n8n\">🚦 Getting started with n8n\u003C/h2>\n\u003Cp>Getting started with n8n was easy. Just connect your Google account and you get access to their free tier. In fact, I was able to complete my entire project on this tier.\u003C/p>\n\u003Cp>You start by creating a new workflow and establishing your trigger. If I were setting this up for real, I would have chosen a scheduled trigger to pull and refresh data periodically, or have triggered it via a Webhook when data changed. For my initial exploration I went with a manual trigger to keep things simple.\u003C/p>\n\u003Cp>The n8n UI is intuitive, and I was able to get going quickly. As a habitual ChatGPT user, I had it open on the side and relied on it to support me throughout the process. While there is an AI chatbot embedded in n8n, I felt more comfortable with the familiar GPT interface. I’ll dig deeper into n8n’s own AI capabilities as I build out future automations.\u003C/p>\n\u003Cp style=\"text-align: center;\">\u003Cb>n8 Workflow Canvas\u003C/b>\u003C/p>\n\u003Ccenter>\u003Cimg src=\"/images/02-n8n-workflow-canvas.png\" style=\"width:700px\">\u003C/center>\n\u003Ch2 id=\"-pulling-data-from-theirstack\">🎣 Pulling data from TheirStack\u003C/h2>\n\u003Cp>With n8n set up and ready to go, my next step was to pull the technology usage data directly from TheirStack. Conveniently, they provide an n8n integration button that lets you copy the required HTTP request and simply paste it to your n8n workflow, automatically creating the node for you.\u003C/p>\n\u003Cp>Of course, things are rarely seamless the first time around. There was some initial messing about figuring out how to obtain my API Key and correctly add it to the node configuration. After a bit of trial and error, I got the connection working, only to realise I needed a paid TheirStack subscription to fully enable the API. Subscription sorted, I successfully pulled the data using the handy “Test Workflow” feature built into n8n.\u003C/p>\n\u003Cp>With the data flowing, the next step was straightforward. I connected a Google Sheets node to my workflow. With just a few clicks, I mapped the JSON data fields to columns in my Google Sheet and was able to populate a single row.\u003C/p>\n\u003Cp>At this stage, things got a little tricky. I wanted to populate 500 records, the maximum my TheirStack account would allow via the API (you have to be a superuser to do more), so I would have a representative set of n8n customers from major economies. I had some difficulties because I couldn’t get my workflow to loop through each record in turn. I initially went down the road of using a “Loop Over Items” node to try and solve for this but struggled to get that working.\u003C/p>\n\u003Cp>I made a breakthrough when I realized I could share the input and output data from a node with ChatGPT by copying and pasting it, providing some context. ChatGPT understood my issue and suggested using a Code node to break down my large dataset into individual records.\u003C/p>\n\u003Cp>I haven’t really been let loose on code since my early days as a Java programmer back in the early 2000s, and aside from some basic scripting for demos in various pre-sales roles, my coding skills are a little rusty. Thankfully, having GPT generate any necessary code worked just fine throughout this project. Sometimes it took a few attempts, but we always got there.\u003C/p>\n\u003Cp>With that hurdle overcome, I had a fully populated Google Sheet containing my 500 records, ready for further enrichment and analysis.\u003C/p>\n\u003Ch2 id=\"-enriching-the-dirty-data\">🧼 Enriching the dirty data\u003C/h2>\n\u003Cp>With my dataset now safely stored in Google Sheets, the next challenge emerged: addressing the patchy or incomplete data I’d mentioned earlier. Missing or inconsistent data points such as industry classification, revenue, or employee counts posed a problem for the upcoming ICP analysis. I needed complete and consistent firmographic data to ensure accurate, meaningful insights.\u003C/p>\n\u003Cp>To solve this I used a simple “If” node in n8n to check for missing data, routing any problematic records to an OpenAI node for enrichment. It was crucial to be explicit with GPT-4, ensuring it always used a consistent output format. After some trial and error, I had a prompt that worked consistently.\u003C/p>\n\u003Cp style=\"text-align: center;\">\u003Cb>GPT Enrichment Prompt\u003C/b>\u003C/p>\n\u003Ccenter>\u003Cimg src=\"/images/03-gpt-prompt.png\" style=\"width:700px\">\u003C/center>\n\u003Cp>This structured approach allowed GPT-4 to reliably fill in gaps without adding unnecessary noise. Once enriched, I fed the cleaned data back into Google Sheets, resulting in a fully structured and reliable dataset. My previously “dirty” data was now clean, complete, and ready for ICP analysis.\u003C/p>\n\u003Cp style=\"text-align: center;\">\u003Cb>Final n8n Enrichment Workflow\u003C/b>\u003C/p>\n\u003Ccenter>\u003Cimg src=\"/images/04-final-workflow.png\" style=\"width:700px\">\u003C/center>\n\u003Ch2 id=\"-summarizing-data-and-running-icp-analysis\">🧠 Summarizing data and running ICP analysis\u003C/h2>\n\u003Cp>With my clean list of 500 n8n customers and their firmographic details in place, the next step was to segment the data. Alongside basic counts by industry and country I needed to bucket the numerical data (revenue and number of employees) into segments like “Small, Medium, Large” for easy analysis. To do this I used a “Summarize” node to split the data as required.\u003C/p>\n\u003Cp>Soon I hit another roadbump in that OpenAI was struggling to make sense of the multiple datasets and would seem to hang thinking. With some help from n8n’s AI assistant (which accesses documentation and community content) I was able to create a simple input for the LLM with an “Edit Fields” node and another Code node.\u003C/p>\n\u003Ch2 id=\"-ai-powered-icp-generation\">✨ AI-Powered ICP generation\u003C/h2>\n\u003Cp>With the data ready for analysis the next step was to have GPT do the ICP analysis. To do this I crafted the prompt shown below, referencing my summarized data. I kept it simple for illustration. Much more would be possible with richer input data.\u003C/p>\n\u003Cp style=\"text-align: center;\">\u003Cb>GPT ICP Prompt\u003C/b>\u003C/p>\n\u003Ccenter>\u003Cimg src=\"/images/05-icp-prompt.png\" style=\"width:700px\">\u003C/center>\n\u003Cp>The final step was automating the delivery of insights. By connecting n8n directly to Google Docs using OAuth, the AI-generated ICP analysis was formatted and ready for easy sharing. Note: In reality, I would spend more time on formatting, but as a proof of concept this was good to go.\u003C/p>\n\u003Cp style=\"text-align: center;\">\u003Cb>ICP Analysis in Google Doc\u003C/b>\u003C/p>\n\u003Ccenter>\u003Cimg src=\"/images/06-gdoc-output-ICP.png\" style=\"width:700px\">\u003C/center>\n\u003Cp>I did all of the summarizing and ICP analysis and Google Doc steps in a separate workflow. I’m sure I could have done it in one, but breaking it up kept the overall layout manageable.\u003C/p>\n\u003Cp style=\"text-align: center;\">\u003Cb>Summarizing and ICP Analysis\u003C/b>\u003C/p>\n\u003Ccenter>\u003Cimg src=\"/images/07-second-workflow.png\" style=\"width:700px\">\u003C/center>\n\u003Ch2 id=\"-lessons-learned\">🎓 Lessons learned\u003C/h2>\n\u003Cp>Using n8n to automate this workflow was next level vs using GPT as a copilot. Whilst I could (and have) got to similar outputs through prompting alone, and manually manipulating spreadsheets, using automation to solidify a repeatable workflow will be a game changer in time saved for this kind of analysis moving forward.\u003C/p>\n\u003Cp>Key takeaways from this journey:\u003C/p>\n\u003Cul>\n\u003Cli>\u003Cstrong>Prep is critical\u003C/strong>: Enrich before you analyze.\u003C/li>\n\u003Cli>\u003Cstrong>n8n as glue\u003C/strong>: Seamlessly connects tools.\u003C/li>\n\u003Cli>\u003Cstrong>LLMs in automation\u003C/strong>: Move beyond prompting—enable repeatable, scalable insight generation.\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"-final-thoughts\">🏁 Final thoughts\u003C/h2>\n\u003Cp>My ICP analysis was simple, focusing only on firmographic data, as a proof of concept. In reality, to build out the full ICP, I would be bringing in multiple 1st party data sources, to augment 3rd party, and analysing technographics, psychographics, business situation and operating model too.\u003C/p>\n\u003Cp>n8n is clearly a powerful centerpoint for automating and scaling modern marketing operations. This leaves me with an excellent first impression of a platform truly positioned at the intersection of low-code and AI. I’m looking forward to experimenting with some additional automations to take on more of the product marketing playbook, like identifying use case clusters or supporting segmentation-driven GTM plays.\u003C/p>\n\u003Cblockquote>\n\u003Cp>As a product marketer, what excites me most is how n8n enables not just automation, but repeatable insight generation—unlocking many opportunities for faster GTM cycles, richer segmentation, and smarter decisions at scale.\u003C/p>\n\u003C/blockquote>",{"headings":23,"localImagePaths":52,"remoteImagePaths":53,"frontmatter":54,"imagePaths":56},[24,28,31,34,37,40,43,46,49],{"depth":25,"slug":26,"text":27},2,"-toolkit-overview","🧰 Toolkit overview",{"depth":25,"slug":29,"text":30},"-theirstack-my-source-of-tech-truth","🥞 TheirStack: My source of tech truth",{"depth":25,"slug":32,"text":33},"-getting-started-with-n8n","🚦 Getting started with n8n",{"depth":25,"slug":35,"text":36},"-pulling-data-from-theirstack","🎣 Pulling data from TheirStack",{"depth":25,"slug":38,"text":39},"-enriching-the-dirty-data","🧼 Enriching the dirty data",{"depth":25,"slug":41,"text":42},"-summarizing-data-and-running-icp-analysis","🧠 Summarizing data and running ICP analysis",{"depth":25,"slug":44,"text":45},"-ai-powered-icp-generation","✨ AI-Powered ICP generation",{"depth":25,"slug":47,"text":48},"-lessons-learned","🎓 Lessons learned",{"depth":25,"slug":50,"text":51},"-final-thoughts","🏁 Final thoughts",[],[],{"title":14,"description":15,"date":55},["Date","2025-05-21T00:00:00.000Z"],[],"n8n-icp-workflow.md"]